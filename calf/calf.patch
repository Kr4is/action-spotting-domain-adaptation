diff --git a/Benchmarks/CALF/src/dataset.py b/Benchmarks/CALF/src/dataset.py
index 1c80fe9..7ee0562 100644
--- a/Benchmarks/CALF/src/dataset.py
+++ b/Benchmarks/CALF/src/dataset.py
@@ -21,13 +21,19 @@ from config.classes import EVENT_DICTIONARY_V2, K_V2
 
 from preprocessing import oneHotToShifts, getTimestampTargets, getChunks_anchors
 
-
+def inferListGame(SoccerNet_path): 
+    list_games = []
+    for root, dirs, files in os.walk(SoccerNet_path):
+        for file in files:
+            if file.endswith(".json"):
+                list_games.append(os.path.relpath(root, SoccerNet_path))
+    return list_games
 
 class SoccerNetClips(Dataset):
     def __init__(self, path, features="ResNET_PCA512.npy", split="train", 
                 framerate=2, chunk_size=240, receptive_field=80, chunks_per_epoch=6000):
         self.path = path
-        self.listGames = getListGames(split)
+        self.listGames = inferListGame(path)
         self.features = features
         self.chunk_size = chunk_size
         self.receptive_field = receptive_field
@@ -160,7 +166,7 @@ class SoccerNetClipsTesting(Dataset):
     def __init__(self, path, features="ResNET_PCA512.npy", split="test", 
                 framerate=2, chunk_size=240, receptive_field=80):
         self.path = path
-        self.listGames = getListGames(split)
+        self.listGames = inferListGame(path)
         self.features = features
         self.chunk_size = chunk_size
         self.receptive_field = receptive_field
@@ -174,11 +180,11 @@ class SoccerNetClipsTesting(Dataset):
         self.split=split
 
         logging.info("Checking/Download features and labels locally")
-        downloader = SoccerNetDownloader(path)
-        if split == "challenge":
-            downloader.downloadGames(files=[f"1_{self.features}", f"2_{self.features}"], split=[split], verbose=False)
-        else:       
-            downloader.downloadGames(files=[self.labels, f"1_{self.features}", f"2_{self.features}"], split=[split], verbose=False)
+        # downloader = SoccerNetDownloader(path)
+        # if split == "challenge":
+        #     downloader.downloadGames(files=[f"1_{self.features}", f"2_{self.features}"], split=[split], verbose=False)
+        # else:       
+        #     downloader.downloadGames(files=[self.labels, f"1_{self.features}", f"2_{self.features}"], split=[split], verbose=False)
 
 
 
diff --git a/Benchmarks/CALF/src/main.py b/Benchmarks/CALF/src/main.py
index 6a192ae..cd35cfb 100644
--- a/Benchmarks/CALF/src/main.py
+++ b/Benchmarks/CALF/src/main.py
@@ -80,14 +80,15 @@ def main(args):
     checkpoint = torch.load(os.path.join("models", args.model_name, "model.pth.tar"))
     model.load_state_dict(checkpoint['state_dict'])
 
-    a_mAP, a_mAP_per_class, a_mAP_visible, a_mAP_per_class_visible, a_mAP_unshown, a_mAP_per_class_unshown = test(test_loader, model=model, model_name=args.model_name, save_predictions=True)
-    logging.info("Best performance at end of training ")
-    logging.info("Average mAP: " +  str(a_mAP))
-    logging.info("Average mAP visible: " +  str( a_mAP_visible))
-    logging.info("Average mAP unshown: " +  str( a_mAP_unshown))
-    logging.info("Average mAP per class: " +  str( a_mAP_per_class))
-    logging.info("Average mAP visible per class: " +  str( a_mAP_per_class_visible))
-    logging.info("Average mAP unshown per class: " +  str( a_mAP_per_class_unshown))
+    for metric in ['loose', 'tight']:
+        a_mAP, a_mAP_per_class, a_mAP_visible, a_mAP_per_class_visible, a_mAP_unshown, a_mAP_per_class_unshown = test(test_loader, model=model, model_name=args.model_name, save_predictions=True, metric=metric)
+        # logging.info("Best performance at end of training ")
+        # logging.info(f"{metric} Average mAP: " +  str(a_mAP))
+        # logging.info(f"{metric} Average mAP visible: " +  str( a_mAP_visible))
+        # logging.info(f"{metric} Average mAP unshown: " +  str( a_mAP_unshown))
+        # logging.info(f"{metric} Average mAP per class: " +  str( a_mAP_per_class))
+        # logging.info(f"{metric} Average mAP visible per class: " +  str( a_mAP_per_class_visible))
+        # logging.info(f"{metric} Average mAP unshown per class: " +  str( a_mAP_per_class_unshown))
 
     return a_mAP
 
diff --git a/Benchmarks/CALF/src/train.py b/Benchmarks/CALF/src/train.py
index 2293127..47d4574 100644
--- a/Benchmarks/CALF/src/train.py
+++ b/Benchmarks/CALF/src/train.py
@@ -9,6 +9,18 @@ import math
 from preprocessing import batch2long, timestamps2long
 from json_io import predictions2json
 from SoccerNet.Downloader import getListGames
+from SoccerNet.Evaluation.ActionSpotting import evaluate
+from SoccerNet.Evaluation.utils import EVENT_DICTIONARY_V2, INVERSE_EVENT_DICTIONARY_V2
+from SoccerNet.Evaluation.utils import EVENT_DICTIONARY_V1, INVERSE_EVENT_DICTIONARY_V1
+from tabulate import tabulate
+
+def inferListGame(SoccerNet_path): 
+    list_games = []
+    for root, dirs, files in os.walk(SoccerNet_path):
+        for file in files:
+            if file.endswith(".json"):
+                list_games.append(os.path.relpath(root, SoccerNet_path))
+    return list_games
 
 def trainer(train_loader,
             val_loader,
@@ -186,7 +198,7 @@ def train(dataloader,
     return losses.avg
 
 
-def test(dataloader,model, model_name, save_predictions=False):
+def test(dataloader, model, model_name, save_predictions=True, metric='loose'):
     batch_time = AverageMeter()
     data_time = AverageMeter()
     losses = AverageMeter()
@@ -259,19 +271,44 @@ def test(dataloader,model, model_name, save_predictions=False):
 
     # Save the predictions to the json format
     if save_predictions:
-        list_game = getListGames(dataloader.dataset.split)
+        list_game = inferListGame(dataloader.dataset.path)
         for index in np.arange(len(list_game)):
             predictions2json(detections_numpy[index*2], detections_numpy[(index*2)+1],"outputs/", list_game[index], model.framerate)
 
-
     # Compute the performances
     a_mAP, a_mAP_per_class, a_mAP_visible, a_mAP_per_class_visible, a_mAP_unshown, a_mAP_per_class_unshown = average_mAP(targets_numpy, detections_numpy, closests_numpy, model.framerate)
     
-    print("Average mAP: ", a_mAP)
-    print("Average mAP visible: ", a_mAP_visible)
-    print("Average mAP unshown: ", a_mAP_unshown)
-    print("Average mAP per class: ", a_mAP_per_class)
-    print("Average mAP visible per class: ", a_mAP_per_class_visible)
-    print("Average mAP unshown per class: ", a_mAP_per_class_unshown)
+    # print("Average mAP: ", a_mAP)
+    # print("Average mAP visible: ", a_mAP_visible)
+    # print("Average mAP unshown: ", a_mAP_unshown)
+    # print("Average mAP per class: ", a_mAP_per_class)
+    # print("Average mAP visible per class: ", a_mAP_per_class_visible)
+    # print("Average mAP unshown per class: ", a_mAP_per_class_unshown)
+
+    results =  evaluate(SoccerNet_path=dataloader.dataset.path, 
+                 dataset = None,
+                 Predictions_path="outputs/",
+                 prediction_file=None, 
+                 metric=metric,
+                 EVENT_DICTIONARY=EVENT_DICTIONARY_V2)
+
+    rows = []
+    for i in range(len(results['a_mAP_per_class'])):
+        label = INVERSE_EVENT_DICTIONARY_V2[i]
+        rows.append((
+            label,
+            '{:0.2f}'.format(results['a_mAP_per_class'][i] * 100),
+            '{:0.2f}'.format(results['a_mAP_per_class_visible'][i] * 100),
+            '{:0.2f}'.format(results['a_mAP_per_class_unshown'][i] * 100)
+        ))
+    rows.append((
+        'Average mAP',
+        '{:0.2f}'.format(results['a_mAP'] * 100),
+        '{:0.2f}'.format(results['a_mAP_visible'] * 100),
+        '{:0.2f}'.format(results['a_mAP_unshown'] * 100)
+    ))
+
+    print('Metric:', metric)
+    print(tabulate(rows, headers=['', 'Any', 'Visible', 'Unseen']))
 
     return a_mAP, a_mAP_per_class, a_mAP_visible, a_mAP_per_class_visible, a_mAP_unshown, a_mAP_per_class_unshown
\ No newline at end of file
diff --git a/Features/ExtractResNET_TF2.py b/Features/ExtractResNET_TF2.py
index c7fe5c0..20cd1ae 100644
--- a/Features/ExtractResNET_TF2.py
+++ b/Features/ExtractResNET_TF2.py
@@ -30,6 +30,13 @@ from SoccerNet.utils import getListGames
 from SoccerNet.Downloader import SoccerNetDownloader
 from SoccerNet.DataLoader import Frame, FrameCV
 
+def inferListGame(SoccerNet_path): 
+    list_games = []
+    for root, dirs, files in os.walk(SoccerNet_path):
+        for file in files:
+            if file.endswith(".json"):
+                list_games.append(os.path.relpath(root, SoccerNet_path))
+    return list_games
 
 class FeatureExtractor():
     def __init__(self, rootFolder,
@@ -74,7 +81,7 @@ class FeatureExtractor():
             self.model.trainable = False
 
     def extractAllGames(self):
-        list_game = getListGames(self.split)
+        list_game = inferListGame(self.rootFolder)
         for i_game, game in enumerate(tqdm(list_game)):
             try:
                 self.extractGameIndex(i_game)
@@ -82,27 +89,28 @@ class FeatureExtractor():
                 print(f"issue with game {i_game}, {game}")
 
     def extractGameIndex(self, index):
-        print(getListGames(self.split)[index])
+        game = inferListGame(self.rootFolder)[index]
+        print(game)
         if self.video =="224p":
             for vid in ["1_224p.mkv","2_224p.mkv"]:
-                self.extract(video_path=os.path.join(self.rootFolder, getListGames(self.split)[index], vid))
+                self.extract(video_path=os.path.join(self.rootFolder, game, vid))
                 
         elif self.video =="LQ":
             for vid in ["1.mkv","2.mkv"]:
-                self.extract(video_path=os.path.join(self.rootFolder, getListGames(self.split)[index], vid))
+                self.extract(video_path=os.path.join(self.rootFolder, game, vid))
 
         elif self.video == "HQ":
             
             # read config for raw HD video
             config = configparser.ConfigParser()
-            if not os.path.exists(os.path.join(self.rootFolder, getListGames(self.split)[index], "video.ini")) and self.tmp_HQ_videos is not None:
+            if not os.path.exists(os.path.join(self.rootFolder, game, "video.ini")) and self.tmp_HQ_videos is not None:
                 self.mySoccerNetDownloader.downloadVideoHD(
-                    game=getListGames(self.split)[index], file="video.ini")
-            config.read(os.path.join(self.rootFolder, getListGames(self.split)[index], "video.ini"))
+                    game=game, file="video.ini")
+            config.read(os.path.join(self.rootFolder, game, "video.ini"))
 
             # lopp over videos
             for vid in config.sections():
-                video_path = os.path.join(self.rootFolder, getListGames(self.split)[index], vid)
+                video_path = os.path.join(self.rootFolder, game, vid)
 
                 # cehck if already exists, then skip
                 feature_path = video_path[:-4] + f"_{self.feature}_{self.back_end}.npy"
@@ -114,7 +122,7 @@ class FeatureExtractor():
                 remove_afterwards = False
                 if not os.path.exists(video_path) and self.tmp_HQ_videos is not None:
                     remove_afterwards = True
-                    self.mySoccerNetDownloader.downloadVideoHD(game=getListGames(self.split)[index], file=vid)
+                    self.mySoccerNetDownloader.downloadVideoHD(game=game, file=vid)
 
                 # extract feature for video
                 self.extract(video_path=video_path,
diff --git a/Features/ReduceFeaturesPCA.py b/Features/ReduceFeaturesPCA.py
index e66e893..e793ebe 100644
--- a/Features/ReduceFeaturesPCA.py
+++ b/Features/ReduceFeaturesPCA.py
@@ -11,14 +11,21 @@ import pickle as pkl
 
 from tqdm import tqdm
 
-
+def inferListGame(SoccerNet_path): 
+    list_games = []
+    for root, dirs, files in os.walk(SoccerNet_path):
+        for file in files:
+            if file.endswith(".json"):
+                list_games.append(os.path.relpath(root, SoccerNet_path))
+    return list_games
 
 def main(args):
 
     if not os.path.exists(args.pca_file) or not os.path.exists(args.scaler_file):
             
         PCAdata = []
-        for game in tqdm(getListGames("v1")):
+        for game in tqdm(inferListGame(args.soccernet_dirpath)):
+            print(game)
 
             half1 = np.load(os.path.join(args.soccernet_dirpath, game, "1_"+args.features))
             PCAdata.append(half1)
@@ -58,7 +65,7 @@ def main(args):
 
 
     # loop over games in v1
-    for game in tqdm(getListGames(["v1"])):
+    for game in tqdm(inferListGame(args.soccernet_dirpath)):
         for half in [1,2]:
             game_feat = os.path.join(args.soccernet_dirpath, game, f"{half}_{args.features}")
             game_feat_pca = os.path.join(args.soccernet_dirpath, game, f"{half}_{args.features_PCA}")
@@ -72,21 +79,21 @@ def main(args):
                 print(f"{game_feat_pca} already exists")
 
 
-    for game in tqdm(getListGames(["challenge"])):
-        for half in [1,2]:
-            game_feat = os.path.join(args.soccernet_dirpath, game, f"{half}_{args.features}")
-            game_feat_pca = os.path.join(args.soccernet_dirpath, game, f"{half}_{args.features_PCA}")
-            if not os.path.exists(game_feat_pca) or args.overwrite:
-                feat = np.load(game_feat)
+    # for game in tqdm(getListGames(["challenge"])):
+    #     for half in [1,2]:
+    #         game_feat = os.path.join(args.soccernet_dirpath, game, f"{half}_{args.features}")
+    #         game_feat_pca = os.path.join(args.soccernet_dirpath, game, f"{half}_{args.features_PCA}")
+    #         if not os.path.exists(game_feat_pca) or args.overwrite:
+    #             feat = np.load(game_feat)
                 
-                feat = feat - average
+    #             feat = feat - average
                 
-                feat_reduced = pca.transform(feat)
+    #             feat_reduced = pca.transform(feat)
 
-                np.save(game_feat_pca, feat_reduced)
+    #             np.save(game_feat_pca, feat_reduced)
 
-            else:
-                print(f"{game_feat_pca} already exists")
+    #         else:
+    #             print(f"{game_feat_pca} already exists")
 
 if __name__ == "__main__":
     # Argument parser
